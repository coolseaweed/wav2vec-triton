{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Wav2vec2 Huggingface model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "from torchaudio.models.wav2vec2.utils import import_huggingface_model\n",
    "import torch.onnx\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "AUDIO_MAXLEN = 160000\n",
    "MODEL_OUTDIR = Path(\"/models/wav2vec2/1/\")\n",
    "MODEL_OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "HF_REPO_NAME = \"kresnik/wav2vec2-large-xlsr-korean\"\n",
    "ROOT_DIR = '/opt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kresnik/wav2vec2-large-xlsr-korean were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at kresnik/wav2vec2-large-xlsr-korean and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): FeatureExtractor(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): ConvLayerBlock(\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "      )\n",
       "      (1-4): 4 x ConvLayerBlock(\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "      )\n",
       "      (5-6): 2 x ConvLayerBlock(\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (feature_projection): FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (pos_conv_embed): ConvolutionalPositionalEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x EncoderLayer(\n",
       "          (attention): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): FeedForward(\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux): Linear(in_features=1024, out_features=1205, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "original = Wav2Vec2ForCTC.from_pretrained(HF_REPO_NAME)\n",
    "imported = import_huggingface_model(original) \n",
    "imported.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, AUDIO_MAXLEN, requires_grad=True)\n",
    "\n",
    "torch.onnx.export(\n",
    "        imported,         # model being run\n",
    "         dummy_input,       # model input (or a tuple for multiple inputs)\n",
    "         f\"{MODEL_OUTDIR}/model.onnx\",       # where to save the model\n",
    "         export_params=True,  # store the trained parameter weights inside the model file\n",
    "         opset_version=14,    # the ONNX version to export the model to\n",
    "         do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "         input_names = ['input'],   # the model's input names\n",
    "         output_names = ['output'], # the model's output names\n",
    "         dynamic_axes={\n",
    "            'input' : {\n",
    "                0: 'batch_size',\n",
    "                1: 'input_sequence'\n",
    "                },    \n",
    "            'output' : {\n",
    "                0: 'batch_size',\n",
    "                1: 'output_sequence'\n",
    "                }\n",
    "            \n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-23 15:44:41--  https://www.dropbox.com/s/9kpeh8eodshcqhj/common_voice_th_23646850.wav?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.84.18, 2620:100:6034:18::a27d:5412\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.84.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/9kpeh8eodshcqhj/common_voice_th_23646850.wav [following]\n",
      "--2024-01-23 15:44:45--  https://www.dropbox.com/s/dl/9kpeh8eodshcqhj/common_voice_th_23646850.wav\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc90027e405434cb4b55460bc627.dl.dropboxusercontent.com/cd/0/get/CL5n94jmUsw5bzMB2rmocpC-yk5jqRElBegT7gg_BLU_wQbVYwaeQ0TBXlfCHbV3SyQ9x7ZFOtBD165dDUNo165BrtJx3N19pJi9a2aeuT_TCt1LpBwyrnidXjpiFGbyMQwoGNgW6PuA8v8cAKv0m5O2/file?dl=1# [following]\n",
      "--2024-01-23 15:44:46--  https://uc90027e405434cb4b55460bc627.dl.dropboxusercontent.com/cd/0/get/CL5n94jmUsw5bzMB2rmocpC-yk5jqRElBegT7gg_BLU_wQbVYwaeQ0TBXlfCHbV3SyQ9x7ZFOtBD165dDUNo165BrtJx3N19pJi9a2aeuT_TCt1LpBwyrnidXjpiFGbyMQwoGNgW6PuA8v8cAKv0m5O2/file?dl=1\n",
      "Resolving uc90027e405434cb4b55460bc627.dl.dropboxusercontent.com (uc90027e405434cb4b55460bc627.dl.dropboxusercontent.com)... 162.125.84.15, 2620:100:6034:15::a27d:540f\n",
      "Connecting to uc90027e405434cb4b55460bc627.dl.dropboxusercontent.com (uc90027e405434cb4b55460bc627.dl.dropboxusercontent.com)|162.125.84.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 425326 (415K) [application/binary]\n",
      "Saving to: ‘common_voice_th_23646850.wav?dl=1’\n",
      "\n",
      "common_voice_th_236 100%[===================>] 415.36K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-01-23 15:44:47 (11.2 MB/s) - ‘common_voice_th_23646850.wav?dl=1’ saved [425326/425326]\n",
      "\n",
      "--2024-01-23 15:44:47--  https://huggingface.co/airesearch/wav2vec2-large-xlsr-53-th/raw/main/vocab.json\n",
      "Resolving huggingface.co (huggingface.co)... 13.225.131.35, 13.225.131.6, 13.225.131.94, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.225.131.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 762 [text/plain]\n",
      "Saving to: ‘vocab.json’\n",
      "\n",
      "vocab.json          100%[===================>]     762  --.-KB/s    in 0s      \n",
      "\n",
      "2024-01-23 15:44:48 (220 MB/s) - ‘vocab.json’ saved [762/762]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/9kpeh8eodshcqhj/common_voice_th_23646850.wav?dl=1\n",
    "!mv common_voice_th_23646850.wav?dl=1 ${ROOT}/sound.wav\n",
    "!wget https://huggingface.co/airesearch/wav2vec2-large-xlsr-53-th/raw/main/vocab.json \n",
    "!mv vocab.json ${ROOT}/vocab.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/workspace/config/vocab.json\",\"r\",encoding=\"utf-8-sig\") as f:\n",
    "  d = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'볍': 0, '칠': 1, '깊': 2, '뭔': 3, '러': 4, '르': 5, '튀': 6, '쳇': 7, '땀': 8, '픔': 9, '밌': 10, '좁': 11, '찧': 12, '뮬': 13, '했': 14, '연': 15, '핵': 16, '붐': 17, '봇': 18, '궁': 19, '뜸': 20, '넌': 21, '젖': 22, '맏': 23, '벚': 24, '락': 25, '가': 26, '롭': 27, '달': 28, '슐': 29, '컸': 30, '읍': 31, '색': 32, '맛': 33, '닦': 34, '기': 35, '악': 36, '뻗': 37, '팅': 38, '끗': 39, '깝': 40, '후': 41, '소': 42, '끽': 43, '조': 44, '겪': 45, '코': 46, '광': 47, '컨': 48, '올': 49, '큰': 50, '델': 51, '굉': 52, '교': 53, '발': 54, '랍': 55, '난': 56, '맹': 57, '킨': 58, '옵': 59, '삭': 60, '녹': 61, '엄': 62, '마': 63, '쫄': 64, '콜': 65, '넥': 66, '웹': 67, '뻔': 68, '뿐': 69, '엠': 70, '태': 71, '헝': 72, '멕': 73, '괭': 74, '멧': 75, '핀': 76, '냉': 77, '덟': 78, '덕': 79, '딪': 80, '넷': 81, '향': 82, '왜': 83, '모': 84, '협': 85, '요': 86, '궈': 87, '밑': 88, '결': 89, '덤': 90, '팩': 91, '뻑': 92, '씩': 93, '텔': 94, '및': 95, '펀': 96, '벅': 97, '케': 98, '잠': 99, '낼': 100, '팡': 101, '립': 102, '답': 103, '것': 104, '굿': 105, '허': 106, '샌': 107, '응': 108, '깃': 109, '느': 110, '완': 111, '탠': 112, '떠': 113, '갱': 114, '폭': 115, '쥔': 116, '햇': 117, '워': 118, '넣': 119, '짐': 120, '겟': 121, '갖': 122, '낳': 123, '많': 124, '근': 125, '틴': 126, '이': 127, '쓴': 128, '묻': 129, '팰': 130, '봅': 131, '둘': 132, '팻': 133, '랴': 134, '뒷': 135, '즌': 136, '형': 137, '훼': 138, '묶': 139, '씀': 140, '꿨': 141, '탁': 142, '셜': 143, '멋': 144, '북': 145, '뉜': 146, '룰': 147, '환': 148, '훌': 149, '렉': 150, '브': 151, '튼': 152, '귀': 153, '행': 154, '콘': 155, '었': 156, '삼': 157, '경': 158, '샵': 159, '위': 160, '닛': 161, '쉬': 162, '민': 163, '뒤': 164, '셰': 165, '서': 166, '국': 167, '표': 168, '빌': 169, '랙': 170, '데': 171, '곤': 172, '을': 173, '분': 174, '폄': 175, '째': 176, '템': 177, '밀': 178, '궤': 179, '콩': 180, '뇨': 181, '밤': 182, '컵': 183, '익': 184, '옮': 185, '출': 186, '줍': 187, '짖': 188, '또': 189, '켑': 190, '칭': 191, '본': 192, '륙': 193, '작': 194, '꿎': 195, '앱': 196, '맺': 197, '루': 198, '픽': 199, '던': 200, '솜': 201, '딴': 202, '빈': 203, '쥬': 204, '잖': 205, '찢': 206, '댁': 207, '봤': 208, '텼': 209, '릿': 210, '략': 211, '굳': 212, '깬': 213, '늬': 214, '룸': 215, '운': 216, '벳': 217, '춰': 218, '뛴': 219, '릅': 220, '쁘': 221, '텐': 222, '힘': 223, '예': 224, '옛': 225, '헤': 226, '는': 227, '똥': 228, '탈': 229, '백': 230, '킥': 231, '물': 232, '잇': 233, '께': 234, '칫': 235, '석': 236, '렌': 237, '충': 238, '잡': 239, '닝': 240, '끌': 241, '툼': 242, '전': 243, '논': 244, '채': 245, '트': 246, '볕': 247, '킷': 248, '낸': 249, '빅': 250, '렁': 251, '놈': 252, '남': 253, '부': 254, '갚': 255, '쑤': 256, '뤼': 257, '폈': 258, '컫': 259, '병': 260, '고': 261, '박': 262, '황': 263, '콤': 264, '닥': 265, '헐': 266, '늦': 267, '융': 268, '틱': 269, '참': 270, '틈': 271, '띤': 272, '섭': 273, '눈': 274, '희': 275, '장': 276, '배': 277, '해': 278, '헴': 279, '짊': 280, '몰': 281, '놀': 282, '붉': 283, '칼': 284, '뜻': 285, '즐': 286, '벤': 287, '빼': 288, '압': 289, '벨': 290, '복': 291, '능': 292, '곶': 293, '론': 294, '슴': 295, '퓰': 296, '촘': 297, '통': 298, '걸': 299, '확': 300, '꿔': 301, '찬': 302, '썰': 303, '캘': 304, '꽂': 305, '덜': 306, '돔': 307, '일': 308, '뭐': 309, '웠': 310, '겉': 311, '잦': 312, '목': 313, '늠': 314, '셨': 315, '함': 316, '챙': 317, '된': 318, '럼': 319, '삿': 320, '엿': 321, '숭': 322, '술': 323, '껍': 324, '쨌': 325, '얽': 326, '쏠': 327, '농': 328, '등': 329, '걱': 330, '칸': 331, '굶': 332, '청': 333, '먼': 334, '흩': 335, '집': 336, '닳': 337, '왈': 338, '항': 339, '룡': 340, '런': 341, '봉': 342, '송': 343, '란': 344, '딥': 345, '없': 346, '상': 347, '첼': 348, '득': 349, '픈': 350, '별': 351, '씻': 352, '쉰': 353, '겹': 354, '뭇': 355, '흰': 356, '뻘': 357, '탄': 358, '쥐': 359, '긍': 360, '평': 361, '쯤': 362, '앙': 363, '즈': 364, '팔': 365, '돈': 366, '역': 367, '뇌': 368, '짬': 369, '룹': 370, '뵙': 371, '칙': 372, '클': 373, '왔': 374, '대': 375, '독': 376, '값': 377, '뤄': 378, '팀': 379, '맑': 380, '심': 381, '화': 382, '닌': 383, '질': 384, '속': 385, '띵': 386, '털': 387, '쳐': 388, '젤': 389, '뚜': 390, '끓': 391, '홉': 392, '으': 393, '흉': 394, '창': 395, '랄': 396, '끅': 397, '량': 398, '꽁': 399, '깁': 400, '퇴': 401, '곳': 402, '흡': 403, '책': 404, '몸': 405, '안': 406, '펠': 407, '즉': 408, '렇': 409, '용': 410, '덮': 411, '떤': 412, '챔': 413, '뒀': 414, '명': 415, '샤': 416, '넨': 417, '녀': 418, '돗': 419, '방': 420, '않': 421, '격': 422, '뽕': 423, '천': 424, '측': 425, '줬': 426, '스': 427, '멈': 428, '씬': 429, '씨': 430, '킹': 431, '꼽': 432, '각': 433, '섬': 434, '릴': 435, '큼': 436, '땅': 437, '누': 438, '품': 439, '둔': 440, '봐': 441, '쪽': 442, '츠': 443, '흙': 444, '친': 445, '삶': 446, '짧': 447, '왼': 448, '유': 449, '둠': 450, '꼈': 451, '빠': 452, '혹': 453, '튿': 454, '뀐': 455, '류': 456, '동': 457, '녕': 458, '갔': 459, '냄': 460, '맡': 461, '린': 462, '캉': 463, '찍': 464, '때': 465, '곡': 466, '사': 467, '웃': 468, '그': 469, '탓': 470, '겸': 471, '번': 472, '괌': 473, '닭': 474, '럽': 475, '틸': 476, '섣': 477, '강': 478, '투': 479, '름': 480, '율': 481, '벗': 482, '토': 483, '궐': 484, '른': 485, '몫': 486, '람': 487, '갈': 488, '볐': 489, '밖': 490, '륜': 491, '숙': 492, '점': 493, '합': 494, '놨': 495, '랫': 496, '벌': 497, '힌': 498, '체': 499, '좌': 500, '첫': 501, '매': 502, '성': 503, '텅': 504, '톡': 505, '끔': 506, '벽': 507, '곱': 508, '땐': 509, '엇': 510, '최': 511, '얹': 512, '뺀': 513, '티': 514, '빗': 515, '말': 516, '있': 517, '펜': 518, '앤': 519, '훤': 520, '눌': 521, '면': 522, '듬': 523, '랑': 524, '센': 525, '시': 526, '겨': 527, '똑': 528, '툴': 529, '포': 530, '뵈': 531, '정': 532, '변': 533, '젼': 534, '셈': 535, '맙': 536, '뿌': 537, '샀': 538, '릎': 539, '엔': 540, '켈': 541, '저': 542, '겼': 543, '냐': 544, '잽': 545, '혈': 546, '져': 547, '폼': 548, '콧': 549, '윗': 550, '엣': 551, '나': 552, '실': 553, '글': 554, '챠': 555, '렬': 556, '찮': 557, '썩': 558, '쿼': 559, '녘': 560, '직': 561, '증': 562, '옷': 563, '불': 564, '졸': 565, '핏': 566, '잣': 567, '블': 568, '세': 569, '멸': 570, '짓': 571, '닷': 572, '버': 573, '둑': 574, '낫': 575, '졌': 576, '혜': 577, '빨': 578, '줘': 579, '헌': 580, '설': 581, '앨': 582, '보': 583, '개': 584, '낭': 585, '들': 586, '맥': 587, '끼': 588, '납': 589, '도': 590, '텃': 591, '닿': 592, '십': 593, '겠': 594, '뱀': 595, '습': 596, '살': 597, '옹': 598, '꽃': 599, '쫓': 600, '뱃': 601, '걷': 602, '엎': 603, '널': 604, '료': 605, '빛': 606, '젋': 607, '종': 608, '쾌': 609, '쌌': 610, '약': 611, '램': 612, '옴': 613, '핑': 614, '감': 615, '앗': 616, '댐': 617, '녁': 618, '특': 619, '뺏': 620, '쩔': 621, '샐': 622, '뤘': 623, '깨': 624, '낙': 625, '싼': 626, '뱅': 627, '꿈': 628, '폰': 629, '찾': 630, '됩': 631, '렵': 632, '푼': 633, '딱': 634, '쌀': 635, '깡': 636, '노': 637, '쏟': 638, '삐': 639, '지': 640, '샬': 641, '롯': 642, '탑': 643, '쉼': 644, '흑': 645, '옆': 646, '겐': 647, '니': 648, '철': 649, '쌓': 650, '탱': 651, '팽': 652, '낯': 653, '검': 654, '잘': 655, '간': 656, '딩': 657, '캐': 658, '못': 659, '욕': 660, '싶': 661, '덩': 662, '쇄': 663, '라': 664, '랭': 665, '렴': 666, '훨': 667, '처': 668, '든': 669, '년': 670, '슷': 671, '톰': 672, '붙': 673, '밝': 674, '따': 675, '몽': 676, '싸': 677, '효': 678, '를': 679, '얘': 680, '흔': 681, '뢰': 682, '옳': 683, '낮': 684, '땄': 685, '혼': 686, '옥': 687, '퉁': 688, '며': 689, '풍': 690, '쏜': 691, '깔': 692, '껏': 693, '갤': 694, '초': 695, '떨': 696, '껴': 697, '낡': 698, '괄': 699, '짙': 700, '척': 701, '진': 702, '메': 703, '먹': 704, '륵': 705, '끝': 706, '금': 707, '봄': 708, '족': 709, '층': 710, '회': 711, '휴': 712, '랐': 713, '문': 714, '왕': 715, '톨': 716, '필': 717, '손': 718, '파': 719, '접': 720, '묘': 721, '멀': 722, '치': 723, '쌍': 724, '긴': 725, '죠': 726, '망': 727, '숲': 728, '쿨': 729, '핸': 730, '원': 731, '캔': 732, '되': 733, '쿄': 734, '션': 735, '떴': 736, '육': 737, '만': 738, '앞': 739, '씌': 740, '관': 741, '앵': 742, '적': 743, '엷': 744, '뼈': 745, '펌': 746, '춘': 747, '띄': 748, '혔': 749, '갑': 750, '떼': 751, '한': 752, '찔': 753, '뭘': 754, '드': 755, '듣': 756, '쓸': 757, '았': 758, '담': 759, '펴': 760, '두': 761, '디': 762, '비': 763, '멍': 764, '무': 765, '암': 766, '돋': 767, '페': 768, '겁': 769, '휘': 770, '알': 771, '뀌': 772, '녔': 773, '춤': 774, '야': 775, '켰': 776, '잉': 777, '긋': 778, '쁩': 779, '거': 780, '끄': 781, '큐': 782, '뛰': 783, '온': 784, '베': 785, '내': 786, '팍': 787, '움': 788, '탐': 789, '릉': 790, '턱': 791, '벼': 792, '났': 793, '셔': 794, '할': 795, '썼': 796, '얗': 797, '냅': 798, '갓': 799, '헨': 800, '즘': 801, '생': 802, '갠': 803, '에': 804, '구': 805, '맨': 806, '테': 807, '몇': 808, '놓': 809, '츰': 810, '뎌': 811, '촬': 812, '엽': 813, '닮': 814, '험': 815, '밍': 816, '인': 817, '학': 818, '쿠': 819, '믈': 820, '촌': 821, '닐': 822, '굽': 823, '엉': 824, '꽝': 825, '엑': 826, '김': 827, '쪼': 828, '빙': 829, '쿡': 830, '흐': 831, '줄': 832, '쉽': 833, '펄': 834, '랬': 835, '로': 836, '순': 837, '펫': 838, '오': 839, '피': 840, '키': 841, '뇽': 842, '읽': 843, '첸': 844, '률': 845, '듯': 846, '켓': 847, '건': 848, '쭉': 849, '촛': 850, '존': 851, '히': 852, '려': 853, '셀': 854, '좋': 855, '빵': 856, '싱': 857, '막': 858, '돌': 860, '날': 861, '젠': 862, '둥': 863, '잰': 864, '멜': 865, '앉': 866, '머': 867, '땡': 868, '컥': 869, '였': 870, '얇': 871, '휩': 872, '횡': 873, '슨': 874, '짜': 875, '럭': 876, '활': 877, '카': 878, '써': 879, '은': 880, '눠': 881, '뎅': 882, '턴': 883, '킬': 884, '숨': 885, '아': 886, '선': 887, '뜯': 888, '씸': 889, '렘': 890, '링': 891, '플': 892, '뚫': 893, '꽥': 894, '톤': 895, '쓰': 896, '젝': 897, '윤': 898, '팎': 899, '령': 900, '몬': 901, '닫': 902, '곽': 903, '열': 904, '골': 905, '튜': 906, '샘': 907, '돕': 908, '패': 909, '너': 910, '혁': 911, '괘': 912, '젊': 913, '극': 914, '폐': 915, '꿰': 916, '앓': 917, '과': 918, '죄': 919, '권': 920, '외': 921, '주': 922, '산': 923, '젓': 924, '닉': 925, '믹': 926, '의': 927, '띨': 928, '촨': 929, '므': 930, '리': 931, '쏘': 932, '볶': 933, '차': 934, '밴': 935, '렀': 936, '떡': 937, '쩜': 938, '력': 939, '섰': 940, '붓': 941, '듭': 942, '컴': 943, '축': 944, '샷': 945, '룬': 946, '뉴': 947, '텍': 948, '밥': 949, '냥': 950, '꺼': 951, '울': 952, '징': 953, '홍': 954, '끈': 955, '냈': 956, '솟': 957, '띔': 958, '래': 959, '꾸': 960, '틀': 961, '다': 962, '식': 963, '볼': 964, '네': 965, '쇠': 966, '뜨': 967, '꼭': 968, '펼': 969, '님': 970, '잔': 971, '재': 972, '뚝': 973, '솔': 974, '여': 975, '쟁': 976, '삽': 977, '뺑': 978, '흘': 979, '게': 980, '급': 981, '땠': 982, '흥': 983, '딜': 984, '퓨': 985, '곁': 986, '퍼': 987, '렛': 988, '칩': 989, '뷔': 990, '판': 991, '침': 992, '언': 993, '꼬': 994, '길': 995, '껑': 996, '덴': 997, '촉': 998, '잎': 999, '획': 1000, '자': 1001, '딘': 1002, '중': 1003, '받': 1004, '홀': 1005, '제': 1006, '꼼': 1007, '헷': 1008, '추': 1009, '낀': 1010, '바': 1011, '공': 1012, '애': 1013, '더': 1014, '씁': 1015, '홈': 1016, '액': 1017, '떻': 1018, '싹': 1019, '멘': 1020, '신': 1021, '묵': 1022, '잃': 1023, '늪': 1024, '튬': 1025, '깎': 1026, '푹': 1027, '될': 1028, '렷': 1029, '믿': 1030, '음': 1031, '승': 1032, '롬': 1033, '댓': 1034, '갯': 1035, '륭': 1036, '찌': 1037, '쳤': 1038, '록': 1039, '타': 1040, '혐': 1041, '끊': 1042, '뽀': 1043, '입': 1044, '림': 1045, '섯': 1046, '법': 1047, '맞': 1048, '혀': 1049, '슈': 1050, '윙': 1051, '럴': 1052, '냇': 1053, '객': 1054, '염': 1055, '릇': 1056, '착': 1057, '윌': 1058, '렸': 1059, '억': 1060, '영': 1061, '폴': 1062, '딨': 1063, '쩍': 1064, '괴': 1065, '꾼': 1066, '웨': 1067, '뻐': 1068, '밭': 1069, '첩': 1070, '롤': 1071, '얼': 1072, '늘': 1073, '우': 1074, '힐': 1075, '싫': 1076, '짝': 1077, '취': 1078, '됨': 1079, '빚': 1080, '절': 1081, '반': 1082, '어': 1083, '돼': 1084, '호': 1085, '흠': 1086, '맘': 1087, '솥': 1088, '랜': 1089, '낌': 1090, '캠': 1091, '미': 1092, '쌈': 1093, '까': 1094, '셉': 1095, '켐': 1096, '딸': 1097, '새': 1098, '찰': 1099, '쩌': 1100, '업': 1101, '섹': 1102, '듀': 1103, '단': 1104, '닙': 1105, '뮤': 1106, '념': 1107, '퀴': 1108, '핫': 1109, '헬': 1110, '당': 1111, '월': 1112, '콥': 1113, '풀': 1114, '총': 1115, '규': 1116, '릭': 1117, '뿜': 1118, '넛': 1119, '켜': 1120, '웬': 1121, '같': 1122, '견': 1123, '높': 1124, '쁜': 1125, '넉': 1126, '편': 1127, '늉': 1128, '됐': 1129, '임': 1130, '첨': 1131, '군': 1132, '굵': 1133, '곧': 1134, '웅': 1135, '뷰': 1136, '계': 1137, '양': 1138, '프': 1139, '수': 1140, '터': 1141, '잊': 1142, '례': 1143, '커': 1144, '슬': 1145, '덫': 1146, '굴': 1147, '컷': 1148, '쇼': 1149, '넓': 1150, '꿀': 1151, '밋': 1152, '균': 1153, '뺌': 1154, '뗄': 1155, '범': 1156, '셋': 1157, '쥘': 1158, '꿇': 1159, '넘': 1160, '팬': 1161, '뭄': 1162, '깥': 1163, '탬': 1164, '븐': 1165, '욱': 1166, '잭': 1167, '팜': 1168, '쇤': 1169, '짚': 1170, '돛': 1171, '택': 1172, '얻': 1173, '와': 1174, '탕': 1175, '붕': 1176, '련': 1177, '하': 1178, '레': 1179, '섞': 1180, '윈': 1181, '웁': 1182, '띠': 1183, '찻': 1184, '푸': 1185, '현': 1186, '뽑': 1187, '풋': 1188, '엘': 1189, '엡': 1190, '둬': 1191, '좀': 1192, '꼴': 1193, '롱': 1194, '준': 1195, '훈': 1196, '죽': 1197, '챌': 1198, '곰': 1199, '숍': 1200, '크': 1201, '덧': 1202, '|': 859, '[UNK]': 1203, '[PAD]': 1204}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "import os\n",
    "from pythainlp.util import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100000\n",
    "new_rate = 16000\n",
    "AUDIO_MAXLEN = input_size\n",
    "ort_session = onnxruntime.InferenceSession(f'{MODEL_OUTDIR}/model.onnx') # load onnx model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict((v,k) for k,v in d.items())\n",
    "res[69]=\"[PAD]\"\n",
    "res[68]=\"[UNK]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(x): #\n",
    "  \"\"\"You must call this before padding.\n",
    "  Code from https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/src/wav2vec2/processor.py#L101\n",
    "  Fork TF to numpy\n",
    "  \"\"\"\n",
    "  # -> (1, seqlen)\n",
    "  mean = np.mean(x, axis=-1, keepdims=True)\n",
    "  var = np.var(x, axis=-1, keepdims=True)\n",
    "  return np.squeeze((x - mean) / np.sqrt(var + 1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_adjacent(item): # code from https://stackoverflow.com/a/3460423\n",
    "  nums = list(item)\n",
    "  a = nums[:1]\n",
    "  for item in nums[1:]:\n",
    "    if item != a[-1]:\n",
    "      a.append(item)\n",
    "  return ''.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr(path):\n",
    "    \"\"\"\n",
    "    Code from https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/notebooks/wav2vec2_onnx.ipynb\n",
    "    Fork TF to numpy\n",
    "    \"\"\"\n",
    "    sampling_rate, data = wavfile.read(path)\n",
    "    samples = round(len(data) * float(new_rate) / sampling_rate)\n",
    "    new_data = sps.resample(data, samples)\n",
    "    speech = np.array(new_data, dtype=np.float32)\n",
    "    speech = _normalize(speech)[None]\n",
    "    padding = np.zeros((speech.shape[0], AUDIO_MAXLEN - speech.shape[1]))\n",
    "    speech = np.concatenate([speech, padding], axis=-1).astype(np.float32)\n",
    "    ort_inputs = {\"input\": speech}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    prediction = np.argmax(ort_outs, axis=-1)\n",
    "    # Text post processing\n",
    "    _t1 = ''.join([res[i] for i in list(prediction[0][0])])\n",
    "    return normalize(''.join([remove_adjacent(j) for j in _t1.split(\"[PAD]\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"/workspace/sound.wav\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3164/2770446858.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sampling_rate, data = wavfile.read(path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'บริษัท|เรา|จะ|ต้อง|ปรับตัว|เพื่อ|ใช้งาน|เทคโนโลยี|เหล่านี้'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"บริษัท|เรา|จะ|ต้อง|ปรับตัว|เพื่อ|ใช้งาน|เทคโนโลยี|เหล่านี้\"\n",
    "str2 = \"บริษัท|เรา|จะ|ต้อง|ปรับตัว|เพื่อ|ใช้งาน|เทคโนโลยี|เหล่านี้\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1==str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
